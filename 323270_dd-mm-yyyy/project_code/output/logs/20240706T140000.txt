Standard non-weighted LR
Standard non-weighted LR with reduced dataset
Prior-weighted LR
Quadratic LR
Prior-weighted LR with data preprocessing (data centering)
LR collecting
SVM: linear kernel
SVM linear (c = 1e-05)
SVM linear (c = 3.1622776601683795e-05)
SVM linear (c = 0.0001)
SVM linear (c = 0.00031622776601683794)
SVM linear (c = 0.001)
SVM linear (c = 0.0031622776601683794)
SVM linear (c = 0.01)
SVM linear (c = 0.03162277660168379)
SVM linear (c = 0.1)
SVM linear (c = 0.31622776601683794)
SVM linear (c = 1.0)
SVM: linear kernel with preprocessing
SVM linear (c = 1e-05)
SVM linear (c = 3.1622776601683795e-05)
SVM linear (c = 0.0001)
SVM linear (c = 0.00031622776601683794)
SVM linear (c = 0.001)
SVM linear (c = 0.0031622776601683794)
SVM linear (c = 0.01)
SVM linear (c = 0.03162277660168379)
SVM linear (c = 0.1)
SVM linear (c = 0.31622776601683794)
SVM linear (c = 1.0)
SVM: polynomial kernel
SVM polynomial (c = 1e-05)
SVM polynomial (c = 3.1622776601683795e-05)
SVM polynomial (c = 0.0001)
SVM polynomial (c = 0.00031622776601683794)
SVM polynomial (c = 0.001)
SVM polynomial (c = 0.0031622776601683794)
SVM polynomial (c = 0.01)
SVM polynomial (c = 0.03162277660168379)
SVM polynomial (c = 0.1)
SVM polynomial (c = 0.31622776601683794)
SVM polynomial (c = 1.0)
SVM: RBF kernel
SVM RBF (scale = 0.01831563888873418, c = 0.001)
SVM RBF (scale = 0.01831563888873418, c = 0.0031622776601683794)
SVM RBF (scale = 0.01831563888873418, c = 0.01)
SVM RBF (scale = 0.01831563888873418, c = 0.03162277660168379)
SVM RBF (scale = 0.01831563888873418, c = 0.1)
SVM RBF (scale = 0.01831563888873418, c = 0.31622776601683794)
SVM RBF (scale = 0.01831563888873418, c = 1.0)
SVM RBF (scale = 0.01831563888873418, c = 3.1622776601683795)
SVM RBF (scale = 0.01831563888873418, c = 10.0)
SVM RBF (scale = 0.01831563888873418, c = 31.622776601683793)
SVM RBF (scale = 0.01831563888873418, c = 100.0)
SVM RBF (scale = 0.049787068367863944, c = 0.001)
SVM RBF (scale = 0.049787068367863944, c = 0.0031622776601683794)
SVM RBF (scale = 0.049787068367863944, c = 0.01)
SVM RBF (scale = 0.049787068367863944, c = 0.03162277660168379)
SVM RBF (scale = 0.049787068367863944, c = 0.1)
SVM RBF (scale = 0.049787068367863944, c = 0.31622776601683794)
SVM RBF (scale = 0.049787068367863944, c = 1.0)
SVM RBF (scale = 0.049787068367863944, c = 3.1622776601683795)
SVM RBF (scale = 0.049787068367863944, c = 10.0)
SVM RBF (scale = 0.049787068367863944, c = 31.622776601683793)
SVM RBF (scale = 0.049787068367863944, c = 100.0)
SVM RBF (scale = 0.1353352832366127, c = 0.001)
SVM RBF (scale = 0.1353352832366127, c = 0.0031622776601683794)
SVM RBF (scale = 0.1353352832366127, c = 0.01)
SVM RBF (scale = 0.1353352832366127, c = 0.03162277660168379)
SVM RBF (scale = 0.1353352832366127, c = 0.1)
SVM RBF (scale = 0.1353352832366127, c = 0.31622776601683794)
SVM RBF (scale = 0.1353352832366127, c = 1.0)
SVM RBF (scale = 0.1353352832366127, c = 3.1622776601683795)
SVM RBF (scale = 0.1353352832366127, c = 10.0)
SVM RBF (scale = 0.1353352832366127, c = 31.622776601683793)
SVM RBF (scale = 0.1353352832366127, c = 100.0)
SVM RBF (scale = 0.36787944117144233, c = 0.001)
SVM RBF (scale = 0.36787944117144233, c = 0.0031622776601683794)
SVM RBF (scale = 0.36787944117144233, c = 0.01)
SVM RBF (scale = 0.36787944117144233, c = 0.03162277660168379)
SVM RBF (scale = 0.36787944117144233, c = 0.1)
SVM RBF (scale = 0.36787944117144233, c = 0.31622776601683794)
SVM RBF (scale = 0.36787944117144233, c = 1.0)
SVM RBF (scale = 0.36787944117144233, c = 3.1622776601683795)
SVM RBF (scale = 0.36787944117144233, c = 10.0)
SVM RBF (scale = 0.36787944117144233, c = 31.622776601683793)
SVM RBF (scale = 0.36787944117144233, c = 100.0)
SVM collecting
--Full covariance matrices--
Components: F = 1, T = 1
Components: F = 1, T = 2
Components: F = 1, T = 4
Components: F = 1, T = 8
Components: F = 1, T = 16
Components: F = 1, T = 32
Components: F = 2, T = 1
Components: F = 2, T = 2
Components: F = 2, T = 4
Components: F = 2, T = 8
Components: F = 2, T = 16
Components: F = 2, T = 32
Components: F = 4, T = 1
Components: F = 4, T = 2
Components: F = 4, T = 4
Components: F = 4, T = 8
Components: F = 4, T = 16
Components: F = 4, T = 32
Components: F = 8, T = 1
Components: F = 8, T = 2
Components: F = 8, T = 4
Components: F = 8, T = 8
Components: F = 8, T = 16
Components: F = 8, T = 32
Components: F = 16, T = 1
Components: F = 16, T = 2
Components: F = 16, T = 4
Components: F = 16, T = 8
Components: F = 16, T = 16
Components: F = 16, T = 32
Components: F = 32, T = 1
Components: F = 32, T = 2
Components: F = 32, T = 4
Components: F = 32, T = 8
Components: F = 32, T = 16
Components: F = 32, T = 32
--Diagonal covariance matrices--
Components: F = 1, T = 1
Components: F = 1, T = 2
Components: F = 1, T = 4
Components: F = 1, T = 8
Components: F = 1, T = 16
Components: F = 1, T = 32
Components: F = 2, T = 1
Components: F = 2, T = 2
Components: F = 2, T = 4
Components: F = 2, T = 8
Components: F = 2, T = 16
Components: F = 2, T = 32
Components: F = 4, T = 1
Components: F = 4, T = 2
Components: F = 4, T = 4
Components: F = 4, T = 8
Components: F = 4, T = 16
Components: F = 4, T = 32
Components: F = 8, T = 1
Components: F = 8, T = 2
Components: F = 8, T = 4
Components: F = 8, T = 8
Components: F = 8, T = 16
Components: F = 8, T = 32
Components: F = 16, T = 1
Components: F = 16, T = 2
Components: F = 16, T = 4
Components: F = 16, T = 8
Components: F = 16, T = 16
Components: F = 16, T = 32
Components: F = 32, T = 1
Components: F = 32, T = 2
Components: F = 32, T = 4
Components: F = 32, T = 8
Components: F = 32, T = 16
Components: F = 32, T = 32
Model classification results (no calibration)
Method: LR
Minimum DCF: 0.24363
Actual DCF: 0.49717
LLR: shape = (1, 2000) mean = -0.01204, max = 7.24280, min = -9.48360, devstd = 2.78231
[2.61624501]
[[-1.14357804 -2.23387712 -3.74566451 -2.28959037 -2.59606957]]
Method parameters:
{'variant': 'Quadratic LR', 'Î»': 0.03162277660168379}

Method: SVM
Minimum DCF: 0.17547
Actual DCF: 0.42163
LLR: shape = (1, 2000) mean = 0.17777, max = 7.00166, min = -5.42436, devstd = 2.69045
[1.54521724]
[[-1.14417287 -3.04307376 -3.51435194 -2.8430026  -2.75391073]]
Method parameters:
{'kernel': 'RBF', 'scale': 0.1353352832366127, 'C': 31.622776601683793, 'K': 1}

Method: GMM
Minimum DCF: 0.13124
Actual DCF: 0.15166
LLR: shape = (1, 2000) mean = 0.27733, max = 18.51552, min = -21.54598, devstd = 7.71402
[5.32712446]
[[-3.58715767 -5.38372245 -6.63927654 -6.38332028 -7.87646282]]
Method parameters:
{'variant': 'diag', 'components': (8, 32)}


Score calibration
Calibration of LR
Empirical training prior: 0.01
Empirical training prior: 0.02
Empirical training prior: 0.03
Empirical training prior: 0.04
Empirical training prior: 0.05
Empirical training prior: 0.060000000000000005
Empirical training prior: 0.06999999999999999
Empirical training prior: 0.08
Empirical training prior: 0.09
Empirical training prior: 0.09999999999999999
Empirical training prior: 0.11
Empirical training prior: 0.12
Empirical training prior: 0.13
Empirical training prior: 0.14
Empirical training prior: 0.15000000000000002
Empirical training prior: 0.16
Empirical training prior: 0.17
Empirical training prior: 0.18000000000000002
Empirical training prior: 0.19
Empirical training prior: 0.2
Empirical training prior: 0.21000000000000002
Empirical training prior: 0.22
Empirical training prior: 0.23
Empirical training prior: 0.24000000000000002
Empirical training prior: 0.25
Empirical training prior: 0.26
Empirical training prior: 0.27
Empirical training prior: 0.28
Empirical training prior: 0.29000000000000004
Empirical training prior: 0.3
Empirical training prior: 0.31
Empirical training prior: 0.32
Empirical training prior: 0.33
Empirical training prior: 0.34
Empirical training prior: 0.35000000000000003
Empirical training prior: 0.36000000000000004
Empirical training prior: 0.37
Empirical training prior: 0.38
Empirical training prior: 0.39
Empirical training prior: 0.4
Empirical training prior: 0.41000000000000003
Empirical training prior: 0.42000000000000004
Empirical training prior: 0.43
Empirical training prior: 0.44
Empirical training prior: 0.45
Empirical training prior: 0.46
Empirical training prior: 0.47000000000000003
Empirical training prior: 0.48000000000000004
Empirical training prior: 0.49
Empirical training prior: 0.5
Empirical training prior: 0.51
Empirical training prior: 0.52
Empirical training prior: 0.53
Empirical training prior: 0.54
Empirical training prior: 0.55
Empirical training prior: 0.56
Empirical training prior: 0.5700000000000001
Empirical training prior: 0.5800000000000001
Empirical training prior: 0.59
Empirical training prior: 0.6
Empirical training prior: 0.61
Empirical training prior: 0.62
Empirical training prior: 0.63
Empirical training prior: 0.64
Empirical training prior: 0.65
Empirical training prior: 0.66
Empirical training prior: 0.67
Empirical training prior: 0.68
Empirical training prior: 0.6900000000000001
Empirical training prior: 0.7000000000000001
Empirical training prior: 0.7100000000000001
Empirical training prior: 0.72
Empirical training prior: 0.73
Empirical training prior: 0.74
Empirical training prior: 0.75
Empirical training prior: 0.76
Empirical training prior: 0.77
Empirical training prior: 0.78
Empirical training prior: 0.79
Empirical training prior: 0.8
Empirical training prior: 0.81
Empirical training prior: 0.8200000000000001
Empirical training prior: 0.8300000000000001
Empirical training prior: 0.8400000000000001
Empirical training prior: 0.85
Empirical training prior: 0.86
Empirical training prior: 0.87
Empirical training prior: 0.88
Empirical training prior: 0.89
Empirical training prior: 0.9
Empirical training prior: 0.91
Empirical training prior: 0.92
Empirical training prior: 0.93
Empirical training prior: 0.9400000000000001
Empirical training prior: 0.9500000000000001
Empirical training prior: 0.9600000000000001
Empirical training prior: 0.97
Empirical training prior: 0.98
Empirical training prior: 0.99
Calibration of SVM
Empirical training prior: 0.01
Empirical training prior: 0.02
Empirical training prior: 0.03
Empirical training prior: 0.04
Empirical training prior: 0.05
Empirical training prior: 0.060000000000000005
Empirical training prior: 0.06999999999999999
Empirical training prior: 0.08
Empirical training prior: 0.09
Empirical training prior: 0.09999999999999999
Empirical training prior: 0.11
Empirical training prior: 0.12
Empirical training prior: 0.13
Empirical training prior: 0.14
Empirical training prior: 0.15000000000000002
Empirical training prior: 0.16
Empirical training prior: 0.17
Empirical training prior: 0.18000000000000002
Empirical training prior: 0.19
Empirical training prior: 0.2
Empirical training prior: 0.21000000000000002
Empirical training prior: 0.22
Empirical training prior: 0.23
Empirical training prior: 0.24000000000000002
Empirical training prior: 0.25
Empirical training prior: 0.26
Empirical training prior: 0.27
Empirical training prior: 0.28
Empirical training prior: 0.29000000000000004
Empirical training prior: 0.3
Empirical training prior: 0.31
Empirical training prior: 0.32
Empirical training prior: 0.33
Empirical training prior: 0.34
Empirical training prior: 0.35000000000000003
Empirical training prior: 0.36000000000000004
Empirical training prior: 0.37
Empirical training prior: 0.38
Empirical training prior: 0.39
Empirical training prior: 0.4
Empirical training prior: 0.41000000000000003
Empirical training prior: 0.42000000000000004
Empirical training prior: 0.43
Empirical training prior: 0.44
Empirical training prior: 0.45
Empirical training prior: 0.46
Empirical training prior: 0.47000000000000003
Empirical training prior: 0.48000000000000004
Empirical training prior: 0.49
Empirical training prior: 0.5
Empirical training prior: 0.51
Empirical training prior: 0.52
Empirical training prior: 0.53
Empirical training prior: 0.54
Empirical training prior: 0.55
Empirical training prior: 0.56
Empirical training prior: 0.5700000000000001
Empirical training prior: 0.5800000000000001
Empirical training prior: 0.59
Empirical training prior: 0.6
Empirical training prior: 0.61
Empirical training prior: 0.62
Empirical training prior: 0.63
Empirical training prior: 0.64
Empirical training prior: 0.65
Empirical training prior: 0.66
Empirical training prior: 0.67
Empirical training prior: 0.68
Empirical training prior: 0.6900000000000001
Empirical training prior: 0.7000000000000001
Empirical training prior: 0.7100000000000001
Empirical training prior: 0.72
Empirical training prior: 0.73
Empirical training prior: 0.74
Empirical training prior: 0.75
Empirical training prior: 0.76
Empirical training prior: 0.77
Empirical training prior: 0.78
Empirical training prior: 0.79
Empirical training prior: 0.8
Empirical training prior: 0.81
Empirical training prior: 0.8200000000000001
Empirical training prior: 0.8300000000000001
Empirical training prior: 0.8400000000000001
Empirical training prior: 0.85
Empirical training prior: 0.86
Empirical training prior: 0.87
Empirical training prior: 0.88
Empirical training prior: 0.89
Empirical training prior: 0.9
Empirical training prior: 0.91
Empirical training prior: 0.92
Empirical training prior: 0.93
Empirical training prior: 0.9400000000000001
Empirical training prior: 0.9500000000000001
Empirical training prior: 0.9600000000000001
Empirical training prior: 0.97
Empirical training prior: 0.98
Empirical training prior: 0.99
Calibration of GMM
Empirical training prior: 0.01
Empirical training prior: 0.02
Empirical training prior: 0.03
Empirical training prior: 0.04
Empirical training prior: 0.05
Empirical training prior: 0.060000000000000005
Empirical training prior: 0.06999999999999999
Empirical training prior: 0.08
Empirical training prior: 0.09
Empirical training prior: 0.09999999999999999
Empirical training prior: 0.11
Empirical training prior: 0.12
Empirical training prior: 0.13
Empirical training prior: 0.14
Empirical training prior: 0.15000000000000002
Empirical training prior: 0.16
Empirical training prior: 0.17
Empirical training prior: 0.18000000000000002
Empirical training prior: 0.19
Empirical training prior: 0.2
Empirical training prior: 0.21000000000000002
Empirical training prior: 0.22
Empirical training prior: 0.23
Empirical training prior: 0.24000000000000002
Empirical training prior: 0.25
Empirical training prior: 0.26
Empirical training prior: 0.27
Empirical training prior: 0.28
Empirical training prior: 0.29000000000000004
Empirical training prior: 0.3
Empirical training prior: 0.31
Empirical training prior: 0.32
Empirical training prior: 0.33
Empirical training prior: 0.34
Empirical training prior: 0.35000000000000003
Empirical training prior: 0.36000000000000004
Empirical training prior: 0.37
Empirical training prior: 0.38
Empirical training prior: 0.39
Empirical training prior: 0.4
Empirical training prior: 0.41000000000000003
Empirical training prior: 0.42000000000000004
Empirical training prior: 0.43
Empirical training prior: 0.44
Empirical training prior: 0.45
Empirical training prior: 0.46
Empirical training prior: 0.47000000000000003
Empirical training prior: 0.48000000000000004
Empirical training prior: 0.49
Empirical training prior: 0.5
Empirical training prior: 0.51
Empirical training prior: 0.52
Empirical training prior: 0.53
Empirical training prior: 0.54
Empirical training prior: 0.55
Empirical training prior: 0.56
Empirical training prior: 0.5700000000000001
Empirical training prior: 0.5800000000000001
Empirical training prior: 0.59
Empirical training prior: 0.6
Empirical training prior: 0.61
Empirical training prior: 0.62
Empirical training prior: 0.63
Empirical training prior: 0.64
Empirical training prior: 0.65
Empirical training prior: 0.66
Empirical training prior: 0.67
Empirical training prior: 0.68
Empirical training prior: 0.6900000000000001
Empirical training prior: 0.7000000000000001
Empirical training prior: 0.7100000000000001
Empirical training prior: 0.72
Empirical training prior: 0.73
Empirical training prior: 0.74
Empirical training prior: 0.75
Empirical training prior: 0.76
Empirical training prior: 0.77
Empirical training prior: 0.78
Empirical training prior: 0.79
Empirical training prior: 0.8
Empirical training prior: 0.81
Empirical training prior: 0.8200000000000001
Empirical training prior: 0.8300000000000001
Empirical training prior: 0.8400000000000001
Empirical training prior: 0.85
Empirical training prior: 0.86
Empirical training prior: 0.87
Empirical training prior: 0.88
Empirical training prior: 0.89
Empirical training prior: 0.9
Empirical training prior: 0.91
Empirical training prior: 0.92
Empirical training prior: 0.93
Empirical training prior: 0.9400000000000001
Empirical training prior: 0.9500000000000001
Empirical training prior: 0.9600000000000001
Empirical training prior: 0.97
Empirical training prior: 0.98
Empirical training prior: 0.99
Score fusion
Empirical training prior: 0.01
Empirical training prior: 0.02
Empirical training prior: 0.03
Empirical training prior: 0.04
Empirical training prior: 0.05
Empirical training prior: 0.060000000000000005
Empirical training prior: 0.06999999999999999
Empirical training prior: 0.08
Empirical training prior: 0.09
Empirical training prior: 0.09999999999999999
Empirical training prior: 0.11
Empirical training prior: 0.12
Empirical training prior: 0.13
Empirical training prior: 0.14
Empirical training prior: 0.15000000000000002
Empirical training prior: 0.16
Empirical training prior: 0.17
Empirical training prior: 0.18000000000000002
Empirical training prior: 0.19
Empirical training prior: 0.2
Empirical training prior: 0.21000000000000002
Empirical training prior: 0.22
Empirical training prior: 0.23
Empirical training prior: 0.24000000000000002
Empirical training prior: 0.25
Empirical training prior: 0.26
Empirical training prior: 0.27
Empirical training prior: 0.28
Empirical training prior: 0.29000000000000004
Empirical training prior: 0.3
Empirical training prior: 0.31
Empirical training prior: 0.32
Empirical training prior: 0.33
Empirical training prior: 0.34
Empirical training prior: 0.35000000000000003
Empirical training prior: 0.36000000000000004
Empirical training prior: 0.37
Empirical training prior: 0.38
Empirical training prior: 0.39
Empirical training prior: 0.4
Empirical training prior: 0.41000000000000003
Empirical training prior: 0.42000000000000004
Empirical training prior: 0.43
Empirical training prior: 0.44
Empirical training prior: 0.45
Empirical training prior: 0.46
Empirical training prior: 0.47000000000000003
Empirical training prior: 0.48000000000000004
Empirical training prior: 0.49
Empirical training prior: 0.5
Empirical training prior: 0.51
Empirical training prior: 0.52
Empirical training prior: 0.53
Empirical training prior: 0.54
Empirical training prior: 0.55
Empirical training prior: 0.56
Empirical training prior: 0.5700000000000001
Empirical training prior: 0.5800000000000001
Empirical training prior: 0.59
Empirical training prior: 0.6
Empirical training prior: 0.61
Empirical training prior: 0.62
Empirical training prior: 0.63
Empirical training prior: 0.64
Empirical training prior: 0.65
Empirical training prior: 0.66
Empirical training prior: 0.67
Empirical training prior: 0.68
Empirical training prior: 0.6900000000000001
Empirical training prior: 0.7000000000000001
Empirical training prior: 0.7100000000000001
Empirical training prior: 0.72
Empirical training prior: 0.73
Empirical training prior: 0.74
Empirical training prior: 0.75
Empirical training prior: 0.76
Empirical training prior: 0.77
Empirical training prior: 0.78
Empirical training prior: 0.79
Empirical training prior: 0.8
Empirical training prior: 0.81
Empirical training prior: 0.8200000000000001
Empirical training prior: 0.8300000000000001
Empirical training prior: 0.8400000000000001
Empirical training prior: 0.85
Empirical training prior: 0.86
Empirical training prior: 0.87
Empirical training prior: 0.88
Empirical training prior: 0.89
Empirical training prior: 0.9
Empirical training prior: 0.91
Empirical training prior: 0.92
Empirical training prior: 0.93
Empirical training prior: 0.9400000000000001
Empirical training prior: 0.9500000000000001
Empirical training prior: 0.9600000000000001
Empirical training prior: 0.97
Empirical training prior: 0.98
Empirical training prior: 0.99
Results after calibration / fusion:
Method: LR
Minimum DCF: 0.24293
Actual DCF: 0.24562
LLR: shape = (1, 2000) mean = 0.08307, max = 14.77615, min = -19.58324, devstd = 5.79628
[0.07713266]
[[ 0.46210475 -6.32217963 -5.00239116 -5.73833985 -8.7403332 ]]
Method parameters:
{'training_prior': 0.89}

Method: SVM
Minimum DCF: 0.17929
Actual DCF: 0.17929
LLR: shape = (1, 2000) mean = 0.49708, max = 17.06284, min = -12.32493, devstd = 6.24674
[0.26403778]
[[ 4.38864943 -5.22692212 -7.42735371 -6.67527733 -7.31865976]]
Method parameters:
{'training_prior': 0.21000000000000002}

Method: GMM
Minimum DCF: 0.14599
Actual DCF: 0.14699
LLR: shape = (1, 2000) mean = 0.43265, max = 25.83691, min = -24.05731, devstd = 9.13690
[2.54242201]
[[  7.68722406 -12.19857378  -9.44969757  -6.66407456 -14.04988108]]
Method parameters:
{'training_prior': 0.99}

Method: Fusion
Minimum DCF: 0.11948
Actual DCF: 0.11962
LLR: shape = (1, 2000) mean = 0.19888, max = 22.23829, min = -25.21316, devstd = 8.80273
[2.22000481]
[[  5.51228313  -9.9654011   -8.086228    -6.12458254 -11.67255213]]
Method parameters:
{'training_prior': 0.15000000000000002}


Evaluation on application dataset: LR
Training data/labels: (6, 4000), (4000,)
Validation score/labels: (1, 2000), (2000,)
Evaluation data/labels: (6, 6000) (6000,)
LR Quadratic LR, reg_coeff: 0.03162277660168379, pi_tr = None, pi_app = 0.1
Score calibration: LR, pi_tr = 0.89, pi_app = 0.1
Score type: Validation
LLR: shape = (1, 2000) mean = -0.01204, max = 7.24280, min = -9.48360, devstd = 2.78231
[[-2.69140177 -2.56232629  5.01051459 -2.27944105 -2.44288975]]
[[-1.14357804 -2.23387712 -3.74566451 -2.28959037 -2.59606957]]

Score type: Evaluation - Raw
LLR: shape = (1, 6000) mean = 0.44559, max = 6.67756, min = -5.12444, devstd = 1.85235
[[-2.10540045 -1.87188622  2.25239903 -2.01025171 -1.84870171]]
[[-1.44856268 -0.42500649  0.2300168  -1.16090642  1.12060331]]

Score type: Evaluation - Cal.
LLR: shape = (1, 6000) mean = 1.03311, max = 13.99722, min = -10.55400, devstd = 3.85336
[[-4.27361455 -3.78784405  4.79174479 -4.07568034 -3.73961423]]
[[-2.90722069 -0.7779569   0.58466236 -2.30882065  2.43731455]]


Evaluation on application dataset: SVM
Training data/labels: (6, 4000), (4000,)
Validation score/labels: (1, 2000), (2000,)
Evaluation data/labels: (6, 6000) (6000,)
SVM RBF (rbf), K = 1, C = 31.622776601683793, gamma = 0.1353352832366127, pi_app = 0.1
Score calibration: SVM, pi_tr = 0.21000000000000002, pi_app = 0.1
Score type: Validation
LLR: shape = (1, 2000) mean = 0.17777, max = 7.00166, min = -5.42436, devstd = 2.69045
[[-2.90619222 -3.11213563  2.43048623 -3.19523352 -2.53380834]]
[[-1.14417287 -3.04307376 -3.51435194 -2.8430026  -2.75391073]]

Score type: Evaluation - Raw
LLR: shape = (1, 6000) mean = 1.50811, max = 106.71302, min = -97.75158, devstd = 21.27893
[[-32.4308598  -29.71315915  29.67978038 -97.75157882 -23.82675197]]
[[-37.16580461  -3.01728373   1.86614628 -11.41295786  10.0180009 ]]

Score type: Evaluation - Cal.
LLR: shape = (1, 6000) mean = 3.58278, max = 247.18796, min = -226.25605, devstd = 49.27201
[[ -75.00393824  -68.71101962   68.81514043 -226.25605222  -55.08086456]]
[[-85.96784714  -6.89590717   4.41182371 -26.33634629  23.28769132]]


Evaluation on application dataset: GMM
Training data/labels: (6, 4000), (4000,)
Validation score/labels: (1, 2000), (2000,)
Evaluation data/labels: (6, 6000) (6000,)
GMM diag, components = (8, 32), pi_app = 0.1
Score calibration: GMM, pi_tr = 0.99, pi_app = 0.1
Score type: Validation
LLR: shape = (1, 2000) mean = 0.27733, max = 18.51552, min = -21.54598, devstd = 7.71402
[[-3.68136936 -8.12444903 12.7258423  -6.33492802 -9.15786159]]
[[-3.58715767 -5.38372245 -6.63927654 -6.38332028 -7.87646282]]

Score type: Evaluation - Raw
LLR: shape = (1, 6000) mean = 0.31108, max = 21.20970, min = -24.89061, devstd = 7.77860
[[ -8.36171413 -10.43278232  10.0692637  -17.44797223  -9.30821352]]
[[-9.31255119 -5.19782269  3.60638285 -9.34125759  3.8445342 ]]

Score type: Evaluation - Cal.
LLR: shape = (1, 6000) mean = 0.44406, max = 24.84092, min = -28.97616, devstd = 9.08067
[[ -9.68048155 -12.09822771  11.83567431 -20.2876966  -10.78541633]]
[[-10.79048009  -5.98698346   4.290966   -10.82399167   4.56898172]]


Evaluation on application dataset: Fusion (best)
Training data/labels: (6, 4000), (4000,)
Validation score/labels: (3, 2000), (2000,)
Evaluation data/labels: (6, 6000) (6000,)
LR Quadratic LR, reg_coeff: 0.03162277660168379, pi_tr = None, pi_app = 0.1
SVM RBF (rbf), K = 1, C = 31.622776601683793, gamma = 0.1353352832366127, pi_app = 0.1
GMM diag, components = (8, 32), pi_app = 0.1
Score calibration: Fusion, pi_tr = 0.15000000000000002, pi_app = 0.1
Score type: Validation
LLR: shape = (3, 2000) mean = 0.14769, max = 18.51552, min = -21.54598, devstd = 4.98428
[[-2.69140177 -2.56232629  5.01051459 -2.27944105 -2.44288975]
 [-2.90619222 -3.11213563  2.43048623 -3.19523352 -2.53380834]
 [-3.68136936 -8.12444903 12.7258423  -6.33492802 -9.15786159]]
[[-1.14357804 -2.23387712 -3.74566451 -2.28959037 -2.59606957]
 [-1.14417287 -3.04307376 -3.51435194 -2.8430026  -2.75391073]
 [-3.58715767 -5.38372245 -6.63927654 -6.38332028 -7.87646282]]

Score type: Evaluation - Raw
LLR: shape = (3, 6000) mean = 0.75493, max = 106.71302, min = -97.75158, devstd = 13.13508
[[ -2.10540045  -1.87188622   2.25239903  -2.01025171  -1.84870171]
 [-32.4308598  -29.71315915  29.67978038 -97.75157882 -23.82675197]
 [ -8.36171413 -10.43278232  10.0692637  -17.44797223  -9.30821352]]
[[ -1.44856268  -0.42500649   0.2300168   -1.16090642   1.12060331]
 [-37.16580461  -3.01728373   1.86614628 -11.41295786  10.0180009 ]
 [ -9.31255119  -5.19782269   3.60638285  -9.34125759   3.8445342 ]]

Score type: Evaluation - Cal.
LLR: shape = (1, 6000) mean = 0.36965, max = 22.82874, min = -26.28390, devstd = 8.34753
[[ -9.00627322 -11.08615319  10.67944677 -17.61198966  -9.98630339]]
[[-9.71867487 -5.52306653  3.67992604 -9.92847296  4.12758937]]



